---
title: "ì‹¤ìŠµ AI í”„ë¡œì íŠ¸"
description: "AI ê°œë°œì„ ë§ˆìŠ¤í„°í•˜ê¸° ìœ„í•œ ì‹¤ìš© í”„ë¡œì íŠ¸"
date: 2026-01-31
draft: false
tags: ["í”„ë¡œì íŠ¸", "íŠœí† ë¦¬ì–¼", "ì‹¤ìŠµ"]
categories: ["tutorials"]
---

## ë§Œë“¤ë©´ì„œ ë°°ìš°ê¸°

ì²˜ìŒë¶€í„° ì‹¤ì œ AI ì•±ì„ êµ¬ì¶•í•˜ì„¸ìš”. ê° í”„ë¡œì íŠ¸ì—ëŠ” ì™„ì „í•œ ì½”ë“œì™€ ì„¤ëª…ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ 1: AI ì±—ë´‡ (ì´ˆë³´ì)

**ë§Œë“¤ ê²ƒ:** ë©”ëª¨ë¦¬ê°€ ìˆëŠ” ëŒ€í™”í˜• AI

**ì‹œê°„:** 1-2ì‹œê°„

### ì„¤ì •

```bash
pip install openai streamlit
```

### ì™„ì „í•œ ì½”ë“œ

```python
# chatbot.py
import streamlit as st
from openai import OpenAI
import os

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

st.title("AI ì±—ë´‡ ğŸ¤–")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì±„íŒ… ì…ë ¥
if prompt := st.chat_input("ë§í•´ë³´ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)
    
    # AI ì‘ë‹µ ë°›ê¸°
    with st.chat_message("assistant"):
        response = client.chat.completions.create(
            model="gpt-4",
            messages=st.session_state.messages
        )
        reply = response.choices[0].message.content
        st.write(reply)
    
    # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": reply})
```

### ì‹¤í–‰í•˜ê¸°

```bash
streamlit run chatbot.py
```

**ë°°ìš¸ ê²ƒ:** ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬, Streamlit UI, ì±„íŒ… íˆìŠ¤í† ë¦¬

---

## í”„ë¡œì íŠ¸ 2: ë¬¸ì„œ Q&A (ì¤‘ê¸‰)

**ë§Œë“¤ ê²ƒ:** PDF ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸í•˜ê¸°

**ì‹œê°„:** 2-3ì‹œê°„

### ì„¤ì •

```bash
pip install langchain langchain-openai chromadb pypdf
```

### ì™„ì „í•œ ì½”ë“œ

```python
# doc_qa.py
import streamlit as st
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.document_loaders import PyPDFLoader
import tempfile
import os

st.title("ë¬¸ì„œ Q&A ğŸ“„")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("PDF ì—…ë¡œë“œ", type="pdf")

if uploaded_file:
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name
    
    # ë¬¸ì„œ ì²˜ë¦¬
    with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘..."):
        loader = PyPDFLoader(tmp_path)
        documents = loader.load()
        
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        chunks = splitter.split_documents(documents)
        
        embeddings = OpenAIEmbeddings()
        vectorstore = Chroma.from_documents(chunks, embeddings)
        
        qa = RetrievalQA.from_chain_type(
            llm=ChatOpenAI(),
            retriever=vectorstore.as_retriever(search_kwargs={"k": 3})
        )
    
    os.unlink(tmp_path)
    st.success("ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!")
    
    # Q&A
    question = st.text_input("ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”:")
    if question:
        with st.spinner("ìƒê° ì¤‘..."):
            answer = qa.run(question)
        st.write("**ë‹µë³€:**", answer)
```

### ì‹¤í–‰í•˜ê¸°

```bash
export OPENAI_API_KEY=sk-your-key
streamlit run doc_qa.py
```

**ë°°ìš¸ ê²ƒ:** RAG, PDF ì²˜ë¦¬, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤

---

## í”„ë¡œì íŠ¸ 3: ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ê¸° (ì¤‘ê¸‰)

**ë§Œë“¤ ê²ƒ:** ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ëŠ” AI

**ì‹œê°„:** 1-2ì‹œê°„

### ì„¤ì •

```bash
pip install openai pillow streamlit
```

### ì™„ì „í•œ ì½”ë“œ

```python
# image_caption.py
import streamlit as st
from openai import OpenAI
import base64
from io import BytesIO

client = OpenAI()

st.title("ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ê¸° ğŸ–¼ï¸")

uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"])

if uploaded_file:
    # ì´ë¯¸ì§€ í‘œì‹œ
    st.image(uploaded_file, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
    
    # ìº¡ì…˜ ìƒì„± ë²„íŠ¼
    if st.button("ìº¡ì…˜ ìƒì„±"):
        with st.spinner("ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
            # base64ë¡œ ë³€í™˜
            image_bytes = uploaded_file.read()
            base64_image = base64.b64encode(image_bytes).decode()
            
            # GPT-4 Vision í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4-vision-preview",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }],
                max_tokens=300
            )
            
            caption = response.choices[0].message.content
            st.write("**ìº¡ì…˜:**", caption)
```

**ë°°ìš¸ ê²ƒ:** Vision AI, ì´ë¯¸ì§€ ì²˜ë¦¬, base64 ì¸ì½”ë”©

---

## í”„ë¡œì íŠ¸ 4: AI ì½˜í…ì¸  ìƒì„±ê¸° (ê³ ê¸‰)

**ë§Œë“¤ ê²ƒ:** SEOê°€ ì ìš©ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±ê¸°

**ì‹œê°„:** 3-4ì‹œê°„

### ì„¤ì •

```bash
pip install openai streamlit
```

### ì™„ì „í•œ ì½”ë“œ

```python
# content_generator.py
import streamlit as st
from openai import OpenAI

client = OpenAI()

st.title("AI ì½˜í…ì¸  ìƒì„±ê¸° âœï¸")

# ì…ë ¥ í¼
topic = st.text_input("ì£¼ì œ:")
keywords = st.text_input("í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„):")
tone = st.selectbox("í†¤:", ["ì „ë¬¸ì ", "ìºì£¼ì–¼", "ê¸°ìˆ ì ", "ì¹œê·¼í•œ"])

if st.button("ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±"):
    with st.spinner("ì‘ì„± ì¤‘..."):
        # ê°œìš” ìƒì„±
        outline_prompt = f\"\"\"{topic}ì— ëŒ€í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ê°œìš”ë¥¼ ë§Œë“œì„¸ìš”.
í¬í•¨ì‚¬í•­:
- ì œëª©
- 5ê°œ ì£¼ìš” ì„¹ì…˜ê³¼ ë¶€ì œëª©
- SEO ìµœì í™” ëŒ€ìƒ: {keywords}
í†¤: {tone}\"\"\"
        
        outline = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": outline_prompt}]
        ).choices[0].message.content
        
        st.write("## ê°œìš”")
        st.write(outline)
        
        # ì „ì²´ í¬ìŠ¤íŠ¸ ìƒì„±
        post_prompt = f\"\"\"ì´ ê°œìš”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™„ì „í•œ 1000ë‹¨ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”:

{outline}

ì£¼ì œ: {topic}
í¬í•¨í•  í‚¤ì›Œë“œ: {keywords}
í†¤: {tone}

í¥ë¯¸ë¡­ê³ , SEOì— ìµœì í™”ë˜ë©°, ì˜ˆì œë¥¼ í¬í•¨í•˜ì„¸ìš”.\"\"\"
        
        with st.spinner("ì „ì²´ í¬ìŠ¤íŠ¸ ì‘ì„± ì¤‘..."):
            post = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": post_prompt}],
                temperature=0.7
            ).choices[0].message.content
        
        st.write("## ì „ì²´ í¬ìŠ¤íŠ¸")
        st.write(post)
        
        # ë©”íƒ€ ì„¤ëª… ìƒì„±
        meta_prompt = f"ì´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ìœ„í•œ 155ì SEO ë©”íƒ€ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”:\\n{post[:500]}"
        meta = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": meta_prompt}]
        ).choices[0].message.content
        
        st.write("## ë©”íƒ€ ì„¤ëª…")
        st.code(meta)
```

**ë°°ìš¸ ê²ƒ:** ë‹¤ë‹¨ê³„ AI ì›Œí¬í”Œë¡œìš°, SEO, ì½˜í…ì¸  ìƒì„±

---

## í”„ë¡œì íŠ¸ 5: ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” AI ì—ì´ì „íŠ¸ (ê³ ê¸‰)

**ë§Œë“¤ ê²ƒ:** ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ììœ¨ ì—ì´ì „íŠ¸

**ì‹œê°„:** 3-4ì‹œê°„

### ì™„ì „í•œ ì½”ë“œ

```python
# ai_agent.py
import streamlit as st
from openai import OpenAI
import json
import requests

client = OpenAI()

# ë„êµ¬ ì •ì˜
tools = [{
    "type": "function",
    "function": {
        "name": "search_web",
        "description": "ì›¹ì—ì„œ ì •ë³´ ê²€ìƒ‰",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {"type": "string", "description": "ê²€ìƒ‰ ì¿¼ë¦¬"}
            },
            "required": ["query"]
        }
    }
}, {
    "type": "function",
    "function": {
        "name": "calculate",
        "description": "ìˆ˜í•™ ê³„ì‚° ìˆ˜í–‰",
        "parameters": {
            "type": "object",
            "properties": {
                "expression": {"type": "string", "description": "ìˆ˜í•™ í‘œí˜„ì‹"}
            },
            "required": ["expression"]
        }
    }
}]

def search_web(query):
    # í”Œë ˆì´ìŠ¤í™€ë” - ì‹¤ì œ ê²€ìƒ‰ API í†µí•©
    return f"{query}ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼"

def calculate(expression):
    try:
        return str(eval(expression))
    except:
        return "ê³„ì‚° ì˜¤ë¥˜"

# ì—ì´ì „íŠ¸ ë£¨í”„
def run_agent(user_query):
    messages = [{"role": "user", "content": user_query}]
    
    for _ in range(5):  # ìµœëŒ€ 5ë²ˆ ë°˜ë³µ
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            tools=tools
        )
        
        message = response.choices[0].message
        
        if message.tool_calls:
            # ë„êµ¬ ì‹¤í–‰
            messages.append(message)
            
            for tool_call in message.tool_calls:
                if tool_call.function.name == "search_web":
                    args = json.loads(tool_call.function.arguments)
                    result = search_web(args["query"])
                elif tool_call.function.name == "calculate":
                    args = json.loads(tool_call.function.arguments)
                    result = calculate(args["expression"])
                
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": result
                })
        else:
            return message.content

st.title("AI ì—ì´ì „íŠ¸ ğŸ¤–")

query = st.text_input("ì—ì´ì „íŠ¸ê°€ ë¬´ì—‡ì„ í•˜ê¸¸ ì›í•˜ë‚˜ìš”?")
if query:
    with st.spinner("ì—ì´ì „íŠ¸ ì‘ë™ ì¤‘..."):
        result = run_agent(query)
    st.write(result)
```

**ë°°ìš¸ ê²ƒ:** í•¨ìˆ˜ í˜¸ì¶œ, ì—ì´ì „íŠ¸, ë„êµ¬ ì‚¬ìš©

---

## í”„ë¡œì íŠ¸ 6: í’€ìŠ¤íƒ AI ì•± (ì „ë¬¸ê°€)

**ë§Œë“¤ ê²ƒ:** FastAPI ë°±ì—”ë“œ + React í”„ë¡ íŠ¸ì—”ë“œë¥¼ ê°–ì¶˜ ì™„ì „í•œ ì•±

**ì‹œê°„:** 8-10ì‹œê°„

### ë°±ì—”ë“œ (FastAPI)

```python
# backend/main.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI
import os

app = FastAPI()
client = OpenAI()

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"]
)

class ChatRequest(BaseModel):
    message: str
    history: list = []

@app.post("/chat")
async def chat(request: ChatRequest):
    try:
        messages = request.history + [
            {"role": "user", "content": request.message}
        ]
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages
        )
        
        return {
            "reply": response.choices[0].message.content,
            "usage": dict(response.usage)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health():
    return {"status": "ok"}
```

### í”„ë¡ íŠ¸ì—”ë“œ (React)

```jsx
// frontend/src/App.jsx
import { useState } from 'react';

function App() {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  
  const sendMessage = async () => {
    const newMessages = [...messages, { role: 'user', content: input }];
    setMessages(newMessages);
    setInput('');
    
    const response = await fetch('http://localhost:8000/chat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        message: input,
        history: messages
      })
    });
    
    const data = await response.json();
    setMessages([...newMessages, { role: 'assistant', content: data.reply }]);
  };
  
  return (
    <div className=\"chat-app\">
      <div className=\"messages\">
        {messages.map((msg, i) => (
          <div key={i} className={msg.role}>
            {msg.content}
          </div>
        ))}
      </div>
      <input 
        value={input}
        onChange={(e) => setInput(e.target.value)}
        onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
      />
      <button onClick={sendMessage}>ë³´ë‚´ê¸°</button>
    </div>
  );
}
```

### ë°°í¬

```bash
# ë°±ì—”ë“œ
cd backend
uvicorn main:app --reload

# í”„ë¡ íŠ¸ì—”ë“œ
cd frontend
npm start
```

**ë°°ìš¸ ê²ƒ:** API ë””ìì¸, í’€ìŠ¤íƒ ê°œë°œ, í”„ë¡œë•ì…˜ ë°°í¬

---

## ë‹¤ìŒ ë‹¨ê³„

ì´ í”„ë¡œì íŠ¸ë“¤ì„ ì™„ë£Œí•œ í›„:
1. ê¸°ëŠ¥ ì¶”ê°€ (ì¸ì¦, ë°ì´í„°ë² ì´ìŠ¤, íŒŒì¼ ì—…ë¡œë“œ)
2. í”„ë¡œë•ì…˜ì— ë°°í¬ (Vercel, Railway, AWS)
3. ë‚˜ë§Œì˜ AI ì œí’ˆ ë§Œë“¤ê¸°!

**ë¦¬ì†ŒìŠ¤:**
- OpenAI ë¬¸ì„œ
- LangChain ë¬¸ì„œ
- Streamlit ê°¤ëŸ¬ë¦¬
